# 3. Beehive系统

- 在这一部分，我们将详细介绍Beehive系统的操作。我们首先会讨论去除SIEM所收集数据的噪声和不连续性的方法。然后，我们讨论了企业环境中用于检测错误行为的特征的选择。最后我们会介绍用来生成反常的主机行为事件的无监督学习方法。

## 3.1 数据标准化

- 为了处理上一部分提到的脏数据和不一致数据带来的挑战，Beehive会在正式开始进行行为分析前对这些日志数据进行预处理。我们接下来解释这个程序不同的处理阶段。
- **时间戳标准化**。在运行全球网络的企业中，产生关键日志的设备处于不同的地理位置。此外，这些设备可能会为日志产生不同的时间戳，用他们自己的时区，UTC或者其他时间表示。这就导致了日志条目有了不一致的时间戳，只有被标准化后，进行的分析才能够更加准确。尽管将协调时间设置的任务交给网络管理员对一个小型网络来说是可行的，但面对一个全球化规模的企业而言，这些方法也变得不切实际。
- Beehive解决了这个问题，这个方法就是借助一个公司共同使用的日志管理中心SIEM系统，用它的时间戳$t_{siem}$ 为每一条日志条目标上时间，记录SIEM接收每条日志条目的时间。对每一个发送日志到SIEM系统的设备，我们首先计算一系列时间差值，$△_i$ = $t_{siem}$-$t_{device,i}$（四舍五入到最近的30分钟）代表经过一段较长时间后（比如，一个月）后成的日志条目i。接下来，我们为每个设备确定时间戳的修正值$△{correction}$ ,令它的值为$△_i $， $△_i $ 是造成时间差异的主要原因。将这个修正值应用于每个设备的时间戳，我们就能得到一个标准化的时间戳值，$t_{normalized,i}$,= $t_{device,i}$+$△_{correction}$。在我们的案例中，由于EMC的SIEM系统被配置为使用UTC时间戳，所以$t_{normalized,i}$就等于UTC时间。我们将这种标准化技术应用于网络上能够生产日志数据的每一个设备，将所有的日志时间戳都标准化为UTC。
- **IP地址和主机映射** 。在一个企业环境中，终端主机通过动态主机配置协议(DHCP)连接到网络时，通常在短时间内动态分配IP地址。这就使得在分析时，将日志中记录的IP地址和其所对应的机器匹配变得困难，因为同样的IP地址可以在事件被日志记录后分配给不同的主机。
- 为了解决这个问题，Beehive分析了由SIEM系统收集的DHCP服务器日志，并且构建了一个IP地址与主机的映射（也就是，绑定）数据库。每一对绑定都表示为一个元组{IP地址，主机名，MAC物理地址，开始时间，结束时间}，在一个确定的时间间隔内将IP地址映射到主机。当新的DHCP日志可用时，这个算法每日都被运行，去更新已经存在的绑定。给定绑定的结果数据库，Beehive可以根据标准化的时间戳标识与给定的IP地址来辨认主机。
- **静态IP地址检测**。基于我们构建的映射数据库来查询IP和主机有可能也会失败，因为一个IP地址是可以被静态分配给一个确定的主机的，并不总是动态分配。然而，维持一个静态IP地址的分配表在一个大型企业网络中是非常困难的，并且由管理员所创建的分配表往往是离线或者过时的。因此，Beehive按照下面的方法实现了在静态分配IP的情况下确认主机。
- 在起步阶段，我们首先在所有被收集日志中检索能被找到的IP地址，以此在企业中创建一个活跃IP的地址池，用集合A来表示。接着，我们从已知的只包含动态IP地址的主机所创建的日志中检索IP地址，例如DHCP和VPN日志，来创建一个已知的动态IP地址池，用集合D来表示。然后我们计算集合的差，S=A-D，而S包含了可能的静态IP地址，接着为S中的每一个地址进行DNS反向查询，并且保存结果，到这里起步阶段就完成了。定期的（比如，一天一次），由于新的日志生成，因此我们需要重复这个过程去收集新的IP地址并更新集合A，D，S。然而，与之前不同的是，每次重复这个过程时，我们将S中的IP地址解析为它们对应的主机名，并且将这些名字与之前存储的值进行比较。如果在两次执行中，主机名发生了变化，我们可以推断出给出的IP地址并不是静态分配的，从而我们可以将它移出集合S。通过这种方法，每一次执行，我们都能够删除IP地址池中一部分非静态分配的IP地址。如果Beehive没有找到IP和主机相应的绑定，但是相反在集合S中找到了给出的IP地址，我们就将这个IP地址视作一个静态主机并且使用集合S中找到的主机名。
- **专用主机**。Beehive专注于监视专用主机的行为，专用主机指的是单个用户使用的机器。由于网络配置的连续不断变化，专用主机的列表在一个大型公司是很难去维护的，所以我们从SIEM系统给出的可用数据中去推断专用主机列表。
- 为此目的，我们使用由微软windows域控制器生成的身份认证日志。对企业中的每一个用户，保存每个用户已经进行身份认证的历史记录（也就是登录），以及身份认证的次数和时间。这些信息被保留超过三个月，以此来建立一个精确的用户活动历史记录。在被保留期间的最后，如果这个主机大部分（比如95%）身份认证事件都是由同一个用户完成的，那么就将这台主机视为“专用的”。通过这个过程，我们已经在EMC中识别了超过78000台专用主机。





## 3.2 特征提取

- 我们在日志中提取特征以便描述企业中好的通信的特性。我们的特性选择是由EMC中已知恶意软件行为和策略违反的观察导向的，同样也是由，换句话说，以严格的防火墙政策为形式的外围防御表现，大多数用户的商业方向，以及企业管理主机的同类软件配置。

- 对企业中的每一个特定主机而言，我们每日生成一个特性向量，包含表2中列出的15个特性。这些特性可以被划分为4类：基于被主机连接的新的和不常用的目的地的特性，与主机软件配置有关的特性，与公司政策有关的特性以及基于流量和时间的特性。在下表中我们详细描述了这四种特性。

  | 特性类别   | #                                | 描述                                                     |
  | ---------- | -------------------------------- | -------------------------------------------------------- |
  | 基于目的地 | 1<br>2<br>3<br>4                 | 新的目的地<br>新的                                       |
  | 基于主机   | 5                                | 新的用户代理字符串                                       |
  | 基于政策   | 6<br>7<br/>8<br/>9<br/>10<br/>11 | 阻塞的域<br>阻塞的连接<br>有挑战的域<br>有挑战的连接<br> |
  | 基于流量   | 12<br>13<br>14<br>15             | 连接高峰<br/>域高峰<br/>突发连接<br/>突发域              |

  ​                                              

  **表2：Beehive特性**

  ### 3.2.1 基于目的地的特性

  - 我们感兴趣的是，识别在EMC中与那些与新的、不清楚的或者外部的从未（或非常少）连接过的目的地的通信的主机 ，假定流行的网站更好被管理并且更少可能被盗用，相比之下的话，与不常见的目的连接或许暗含着存在可疑行为的风险（比如，和指挥控制服务器的通信）。

  - **新的目的地**。我们的第一个基于目的地的特征是每天每个主机连接的新的外部目的地的数量。我们随着时间建立了一个内部主机连接过的外部目的历史记录，如果在观察时期内（比如不在历史中）一个目的地从未被企业中的主机连接过，那么在特定的一天我们就将它视作为*新的*。

  - 我们在分析网络代理日志去构建外部目的站点历史的时候遇到了大量问题。在我们最初初级的方法中，我们处理了每一个代理日志，解析了所有为IP地址形式的目的地，并且包含所有历史中被观察到的新目的地。它证明这种初级的方法在运行时间和历史大小上都是不可延伸的。

  - 首先，初级实施需要花费15个小时去处理一天内有用网络代理日志（相当于300000000日志，大约是600GB）。第二，出乎我们意料的是，新的目的地的数量并没有随着时间而减少，在一个月的时间里，历史增长到了4.3百万个唯一的目的地。正如表1中所示，在每天所有唯一的目的地中，有30%~40%（大约有145000）都是新的。在最初的方法中，所有这些新的目的地每天都要被加入到历史中，同样地，历史的大小也会随着时间不确定得增长。

  - 对网络代理日志的进一步检测表明，新的目的地的大部分是内容分发网络（CDNs），云服务（经常使用随机字符串作为其子域），或者是属于主流服务器的IP地址（谷歌，脸书，推特）。为了使**Beehive**具有延展性，我们使用了大量简化数据的技术，包括过滤，自定义白名单（custom whitelisting）以及域折叠。==domain ”folding“==

    **表1：主机不同时间段内的变化，幼稚方法** 

  - 我们首先通过创建一个自定义白名单的方式来过滤掉“流行的”的目的地，在这里，“流行”意味着存在于公司中的主机。白名单包含了外部目的地（包括域和IP子网），这些外部目的地与内部主机的联系次数随着时间会增加到一个阈值（峰值）。表2展示了被白名单过滤掉的网络流量，这个白名单是根据2013年八月第一周的有效数据创建的。100个主机的峰值从一天3亿日志降到了8000万——**Beehive**需要处理的日志的数量减少了74%。

    **表2：通过自定义白名单对数据简化**

  - 除了自定义白名单以外，我们还可以“折叠”目的地，使其成为一个二级域（second-level domain）以便过滤用随机字符串作为子域的服务。我们同样忽略了检索“favicon”（网页图标）的连接——这很可能是由于网摘（bookmark）的原因造成的。最终，我们选择不去解析原始IP（因为大部分合法网站是通过它们的域名被提及的），并且往往将不在白名单中的原始IP视作“新的”。
  - 这些优化使得每日的处理时间从15个小时减少到了大约5个小时。被添加到历史的新的（折叠的）目的地减少到了平均每天28000个。经过4个月的时期（从2013年1月13日到5月13日），我们外部目的地的历史有27万个折叠域，然而在一个月后，用==naive==方法构建起来的历史早已有了43万个域。 

  - **没有白名单参照的新目的地**。我们的第二个基于目的地的特征是对第一个的扩展，但是第二个特征计算新目的地的数量通过一个没有白名单HTTP参考的主机。用户最普遍通过搜索引擎、新闻网站或者广告进入新的站点。在这些情况下，我们期待HTTP参照能够成为我们自定义白名单中的一部分。那些访问新站定而没有被有信誉的来源推荐（或者根本没有推荐者）的主机会被认为更可疑。

  - **不受欢迎的IP目的地**。我们同样对有着原始IP地址的不受欢迎外部目的地感兴趣。我们首先计算与主机相连的既不受欢迎（并不在上述所描述的白名单中）又是IP地址形式的目的地的数量。与不受欢迎的IP相连意味着存在可疑的活动，因为合法的服务器往往都是可以通过它们的域名到达的。接着，我们将主机当天联系的不受欢迎的目的地中IP地址的部分（fraction）也包括在内。尽管偶尔和原始IP地址产生通信的情况是正常的（比如，和CDNs拥有的IP范围通信），但它频繁发生时，那么这种行为就是可疑的。

  ### 3.2.2 基于主机的特性

  - 比起那些学术网络中主机，企业中的主机的具有更加显著的==一致性==。因此我们对主机安装新（潜在未授权的）软件的情况感兴趣。
  - 由于缺乏对主机机器的可见度，并且仅能访问从网络设备收集的日志，所以我们根据包含在HTTP请求头部的用户代理（UA）字符串来推断主机的软件配置。一个用户代理字符串包含了做出请求的应用名称，它的版本，功能以及操作环境。因此，基于主机的特性就是来自主机“新的”UA字符串的数量。
  - 在超过一个月的时间里，我们建立了一个有关每小时UA字符串的历史，在这期间，每一个来自主机被观察的UA字符串都是被存储下来的。然后，如果一个UA字符串与它主机历史中的所有字符串有足够的区分的话，那么它就会被视作为“新的”。编辑距离（也称作莱文斯坦距离）被用作比较UA字符串，去测量字符插入、删除、以及要求将一个字符串转换成另一个的替换的数量。这就允许我们         由于软件更新导致的“新的”UA字符串，只有一个小的子串改变了（比如：版本号）。

  ### 3.2.3 基于策略的特性

  - 公司环境的另一个独特之处是对出站连接执行网络策略。 正如2.2部分所描述的，如果一个外部目的地没有有把握的信誉或者被划分为对员工禁止的类别时，与这个目的地的连接可以被阻塞。阻塞的域（和连接）因此成为了一个粗略的主机错误行为的指示器。
  - 在访问一个*未知* 站点的时候 ，换句话说，这个站点还没有被分类或者被规定，用户必须在允许进入该站点前明确同意公司的策略。我们将需要这种确认的域（和连接）称为*有挑战的* ，将用户已经同意的称为*已同意的*。
  - 我们基于策略的特性包含了上述描述过的三种类型的通信。对一个主机而言，我们计算与之相连的阻塞的、挑战的和已同意的域的数量。

  ### 3.2.4 基于流量的特性

  - 一个主机流量的突然激增（spikes）可能是由恶意软件（比如，扫描，或者回应机器主人命令的机器活动）或自动化进程引起的。我们基于流量的特性试图通过一个主机异常产生高流量的时间量，去捕捉这些有趣的活动。

  - 具体来说，当主机建立的连接超过一个阈值之后（或连接的域），我们定义一个连接（或域）高峰为一个一分钟的窗口。一个连接爆发指的是一个时间段里每一分钟都是一个连接高峰。

  - 为了给“高”流量确定一个合适的阈值，我们在一周的时间间隔内检测了所有专用主机，并且计算了每一个主机每分钟建立（或连接）的连接（和域）的数量。表3展示了所有专用主机在所有一分钟窗口中的累积分布。    90%的主机每分钟建立的连接不到101个，接触的不同的域不到17个。因此，我们将这些数字设置为连接高峰和域高峰的阈值。

    **图三：每分钟主机建立的网络连接和有关的域数量的CDF（累积分布函数）**

  - 对爆发的情况，我们稍微放宽了它的定义，因此突发事件中峰值的阈值是所有主机的所有一分钟窗口的75%（见图三）。连接峰值是26，域峰值是6。

  - 对每一个专用主机，它基于流量的特性包括：1）连接高峰的数量，2）域高峰的数量，3）最长的突发连接持续的时间，4）最长的突发域经历的时间

## 3.3 聚类

- 由于缺乏主机被感染或者异常的事实（我们在2.3章节中提到的挑战），我们通过一种无人监督的学习方法——聚类，来解决这个问题。因为公司的员工在企业网络上做特定的工作，并且在大多数部门中都有多个员工，所以我们应该能够观察一组主机（属于角色相似的用户）表现出相似的行为，而行为模式独特的主机表现出异常。
- 在3.2节中描述了15种特性，每一个内部的主机被看做是一个15维度的向量，$v=(v[1],v[2],....v[15])$。然而，这些特性很可能是彼此关联相互依赖的；例如，一个域峰值会引起一个连接的峰值。为了消除特性之间的依赖性，并且减少向量的维度，我们采用主成分分析（PCA）。
- 简单来说，PCA通过将原始向量投影成一组新的坐标轴（也就是主要成分） 实现数据的缩减。每一个主要成分被选择用来捕捉数据中尽可能多的多样性（因此是原始信息）。依赖于我们想要从原始数据中获得的多样性多少，前m个主要成分被选择出来，允许原始向量的投影减少到维度为m。在**Beehive**中，我们挑选了前m个主要成分，它们至少捕捉了数据多样性中的95%。
- 将聚类算法应用于主成分分析后的投影向量。我们的算法是对K-means（K-均值）算法的一个改编版，不需要提前确定聚类的数量。

  1. 随机选择一个向量作为初始聚类中心。将所有向量分配到这个簇。
  2. 挑选一个离它的聚类中心最远的向量作为一个新的聚类中心。将每个向量重新分配到离它最近的聚类中心下。
  3. 重复第二步，直到没有向量到它中心的距离远于聚类中心之间的距离的一半。
- 我们通过L1距离来比较向量，也就是说，对于向量$v1$和$v2$，它们的L1距离**L1Dist** = $(v1,v2)=\sum_{i=1}^{m}|v1[i]-v2[i]|$ 。
- 在**Beehive**中聚类算法被应用于所有公司中的活跃的专用主机。（我们在工作日观察到活跃的主机有27000~35000个，而在周末则有9000~10100个）。有趣的是，在算法进行了一轮以后，大量的主机都合并成了一个大的簇，而剩余的包含少量的主机的簇则偏离了正常的情况（也就是说，发生了异常）
- **Beehive**为最外围的主机生成了*事件*，并且将它们报告给安全分析员。要注意到，算法通过迭代识别离它聚类中心最远的节点形成了簇，所以簇对这些节点有一个固有的排序。为了防止算法因极端的异常值而受到干扰（比如：只形成两个簇，一个只有一个节点，另一个有其余所有的节点），我们对最大的簇再应用PCA和聚类算法。迭代执行这个过程直到一天内至少有50个偏远主机被识别。
